# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=llama2

# Model Parameters
MAX_TOKENS=2048
TEMPERATURE=0.7
TOP_P=0.9

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false

# Frontend
FRONTEND_PATH=./frontend

# Speech Configuration
WHISPER_MODEL_SIZE=base.en
PIPER_MODEL_PATH=./models/piper/en_US-lessac-medium.onnx
